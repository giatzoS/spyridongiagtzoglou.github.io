---
layout: default
title: Projects
permalink: /projects/
description: "Research projects and code by Spyridon Giagtzoglou."
---

<div class="section-header">
  <h1>Projects &amp; Research</h1>
  <p class="section-subtitle">
    My primary research focuses on convergent training algorithms for generative models, grounded in
    optimization, game theory, and variational inequality theory.
    In parallel, I contribute to an academic project on evaluation metrics for generative models.
    I also explore LLM evaluation as a self-directed side project.
  </p>
</div>

<div class="projects-grid projects-grid--wide">

  <div class="project-card">
    <span class="project-card__badge">PhD Research â€” Core</span>
    <h3>Convergent Algorithms for GAN Training</h3>
    <p>
      Designing GAN training algorithms with an emphasis on <strong>stability</strong> and <strong>provable convergence</strong>
      in adversarial learning.
    </p>

    <div class="project-tags">
      <span class="project-tag">GANs</span>
      <span class="project-tag">Convergence</span>
      <span class="project-tag">Optimization</span>
      <span class="project-tag">Game Theory</span>
      <span class="project-tag">Variational Inequalities</span>
    </div>

    <ul class="project-card__list">
      <li>Formulates training dynamics through game-theoretic / VI perspectives.</li>
      <li>Develops and analyzes convergent update rules.</li>
      <li>Validates behavior via controlled experiments and Python implementations.</li>
    </ul>

    <div class="project-card__meta">
      <i class="fas fa-university" aria-hidden="true"></i>
      Maastricht University, DACS
    </div>
  </div>

  <div class="project-card">
    <span class="project-card__badge">Academic Project</span>
    <h3>Generative AI Evaluation Metrics</h3>
    <p>
      Academic collaboration on <strong>robust mathematical evaluation metrics</strong> for generative models,
      connecting theory with reproducible evaluation pipelines.
    </p>

    <div class="project-tags">
      <span class="project-tag">Generative AI</span>
      <span class="project-tag">Metrics</span>
      <span class="project-tag">Evaluation</span>
      <span class="project-tag">Optimization</span>
      <span class="project-tag">Python</span>
    </div>

    <ul class="project-card__list">
      <li>Studies metric reliability, sensitivity, and failure modes.</li>
      <li>Builds stress tests and benchmarking utilities for comparison and ablation.</li>
      <li>Related manuscripts listed in <strong>Publications</strong>.</li>
    </ul>

    <div class="project-card__meta">
      <i class="fas fa-university" aria-hidden="true"></i>
      Maastricht University, DACS
    </div>
  </div>

  <div class="project-card">
    <span class="project-card__badge">Self-Directed (Side)</span>
    <h3>LLM Evaluation &amp; Reliability Experiments</h3>
    <p>
      Self-paced experimentation on <strong>LLM evaluation</strong>, focusing on reliability, prompt sensitivity,
      and lightweight benchmarking.
    </p>

    <div class="project-tags">
      <span class="project-tag">LLMs</span>
      <span class="project-tag">Evaluation</span>
      <span class="project-tag">Robustness</span>
      <span class="project-tag">Prompting</span>
      <span class="project-tag">Python</span>
    </div>

    <ul class="project-card__list">
      <li>Runs prompt-sensitivity and consistency checks in small-scale setups.</li>
      <li>Maintains notebooks for experiments and reproducibility.</li>
    </ul>

    <div class="project-card__meta">
      <i class="fas fa-code" aria-hidden="true"></i>
      Python &bull; Experiment notebooks
    </div>
  </div>

</div>
